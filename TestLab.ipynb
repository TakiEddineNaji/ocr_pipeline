{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31f8113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STDOUT ===\n",
      "[STEP 1] Processed 1 pages â†’ C:\\ocr-pipeline\\step1_preprocess\\step1_output\n",
      "\n",
      "=== STDERR ===\n",
      "\n",
      "[DEBUG] Script ran successfully\n"
     ]
    }
   ],
   "source": [
    "#STEP 1: Preprocess PDF using a specific Python virtual environment\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Paths\n",
    "pdf_file = r\"C:\\ocr-pipeline\\step1_preprocess\\cv.pdf\"\n",
    "output_folder = r\"C:\\ocr-pipeline\\step1_preprocess\\step1_output\"\n",
    "script_path = r\"C:\\ocr-pipeline\\step1_preprocess\\step1_preprocess_pdf.py\"\n",
    "\n",
    "# Use venv314 Python\n",
    "venv_python = r\"C:\\ocr-pipeline\\ocrproject\\Scripts\\python.exe\"\n",
    "\n",
    "# Run the script and capture output/errors\n",
    "result = subprocess.run(\n",
    "    [venv_python, script_path, pdf_file, output_folder],\n",
    "    capture_output=True,  # Capture stdout and stderr\n",
    "    text=True             # Return output as string (not bytes)\n",
    ")\n",
    "\n",
    "# Show all normal output from the script\n",
    "print(\"=== STDOUT ===\")\n",
    "print(result.stdout)\n",
    "\n",
    "# Show all error messages\n",
    "print(\"=== STDERR ===\")\n",
    "print(result.stderr)\n",
    "\n",
    "# Optional: check if the script succeeded\n",
    "if result.returncode == 0:\n",
    "    print(\"[DEBUG] Script ran successfully\")\n",
    "else:\n",
    "    print(f\"[ERROR] Script failed with return code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa1ae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STDOUT ===\n",
      "OCR â†’ processed_1.png\n",
      "[STEP 2] OCR output saved â†’ C:\\ocr-pipeline\\step2_ocr\\step2_output\\cv_ocr_raw.json\n",
      "\n",
      "=== STDERR ===\n",
      "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n",
      "INFO: Could not find files for the given pattern(s).\n",
      "C:\\ocr-pipeline\\ocrproject\\Lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0102 05:56:35.573367 22464 onednn_context.cc:81] oneDNN v3.6.2\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\latin_PP-OCRv5_mobile_rec`.\u001b[0m\n",
      "C:\\ocr-pipeline\\step2_ocr\\step2_ocr_paddle.py:58: DeprecationWarning: Please use `predict` instead.\n",
      "  ocr_result = ocr.ocr(str(img_path))\n",
      "\n",
      "[DEBUG] OCR script ran successfully\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# STEP 2 CALLER — Run OCR script using a specific venv\n",
    "# =====================================================\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# -------------------------------\n",
    "# Paths\n",
    "# -------------------------------\n",
    "input_folder = r\"C:\\ocr-pipeline\\step1_preprocess\\step1_output\"     # Folder with processed_*.png images\n",
    "output_folder = r\"C:\\ocr-pipeline\\step2_ocr\\step2_output\"               # Folder to save OCR output\n",
    "script_path = r\"C:\\ocr-pipeline\\step2_ocr\\step2_ocr_paddle.py\"      # Path to the OCR script\n",
    "venv_python = r\"C:\\ocr-pipeline\\ocrproject\\Scripts\\python.exe\" # Python from your venv\n",
    "\n",
    "# -------------------------------\n",
    "# Run the OCR script\n",
    "# -------------------------------\n",
    "result = subprocess.run(\n",
    "    [venv_python, script_path, input_folder, output_folder],\n",
    "    capture_output=True,  # Capture stdout and stderr\n",
    "    text=True             # Return output as string\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Show outputs\n",
    "# -------------------------------\n",
    "print(\"=== STDOUT ===\")\n",
    "print(result.stdout)\n",
    "\n",
    "print(\"=== STDERR ===\")\n",
    "print(result.stderr)\n",
    "\n",
    "# -------------------------------\n",
    "# Check if the script succeeded\n",
    "# -------------------------------\n",
    "if result.returncode == 0:\n",
    "    print(\"[DEBUG] OCR script ran successfully\")\n",
    "else:\n",
    "    print(f\"[ERROR] OCR script failed with return code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d88c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STDOUT ===\n",
      "[STEP 3] Cleaned OCR saved â†’ C:\\ocr-pipeline\\step3_lightclean\\step3_output\\cv_ocr_cleaned.json\n",
      "\n",
      "=== STDERR ===\n",
      "\n",
      "[DEBUG] Step 3 OCR cleaning ran successfully\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# STEP 3 CALLER — Run light OCR cleaning using a specific venv\n",
    "# =====================================================\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# -------------------------------\n",
    "# Paths\n",
    "# -------------------------------\n",
    "input_json = r\"C:\\ocr-pipeline\\step2_ocr\\step2_output\\cv_ocr_raw.json\"  # Raw OCR JSON from Step 2\n",
    "output_json = r\"C:\\ocr-pipeline\\step3_lightclean\\step3_output\\cv_ocr_cleaned.json\"  # Cleaned OCR output\n",
    "script_path = r\"C:\\ocr-pipeline\\step3_lightclean\\step3_light_clean.py\"  # Path to Step 3 script\n",
    "venv_python = r\"C:\\ocr-pipeline\\ocrproject\\Scripts\\python.exe\"  # Python from your venv\n",
    "\n",
    "# -------------------------------\n",
    "# Run the Step 3 cleaning script\n",
    "# -------------------------------\n",
    "result = subprocess.run(\n",
    "    [venv_python, script_path, input_json, output_json],\n",
    "    capture_output=True,  # Capture stdout and stderr\n",
    "    text=True             # Return output as string\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Show outputs\n",
    "# -------------------------------\n",
    "print(\"=== STDOUT ===\")\n",
    "print(result.stdout)\n",
    "\n",
    "print(\"=== STDERR ===\")\n",
    "print(result.stderr)\n",
    "\n",
    "# -------------------------------\n",
    "# Check if the script succeeded\n",
    "# -------------------------------\n",
    "if result.returncode == 0:\n",
    "    print(\"[DEBUG] Step 3 OCR cleaning ran successfully\")\n",
    "else:\n",
    "    print(f\"[ERROR] Step 3 OCR cleaning failed with return code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8426e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP 1] Processed 1 pages → C:\\ocr-pipeline\\step1_preprocess\\step1_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ocr-pipeline\\ocrproject\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n",
      "c:\\ocr-pipeline\\ocrproject\\Lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\latin_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR → processed_1.png\n",
      "[STEP 2] OCR output saved → C:\\ocr-pipeline\\step2_ocr\\step2_output\\cv_ocr_raw.json\n",
      "[STEP 3] Cleaned OCR saved → C:\\ocr-pipeline\\step3_lightclean\\step3_output\\cv_ocr_cleaned.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'image': 'processed_1.png',\n",
       "  'lines': [{'text': 'EXPERIENCES / PROJETS',\n",
       "    'confidence': 0.9983910918235779,\n",
       "    'bbox': None},\n",
       "   {'text': 'APPRENTISSAGE EN DATA SCIENCE - AUTOFORMATION /',\n",
       "    'confidence': 0.9963175058364868,\n",
       "    'bbox': None},\n",
       "   {'text': 'PROJETS PERSONNELS',\n",
       "    'confidence': 0.9998707175254822,\n",
       "    'bbox': None},\n",
       "   {'text': '2024 - Present', 'confidence': 0.9953369498252869, 'bbox': None},\n",
       "   {'text': 'Formation en Data Science et Machine Learning (Python, Pandas)',\n",
       "    'confidence': 0.9953547716140747,\n",
       "    'bbox': None},\n",
       "   {'text': \"FORMATEUR / RESPONSABLE PEDAGOGIQUE - SUP'CENTER,\",\n",
       "    'confidence': 0.9918887615203857,\n",
       "    'bbox': None},\n",
       "   {'text': 'MARRAKECH', 'confidence': 0.9997824430465698, 'bbox': None},\n",
       "   {'text': '2019 - 2022', 'confidence': 0.9818785190582275, 'bbox': None},\n",
       "   {'text': 'NAJI', 'confidence': 0.9994564056396484, 'bbox': None},\n",
       "   {'text': 'Soutien en eco internationale/developpement et informatique de gestion',\n",
       "    'confidence': 0.9998278021812439,\n",
       "    'bbox': None},\n",
       "   {'text': 'Enseignement en ligne et presentiel',\n",
       "    'confidence': 0.9853977560997009,\n",
       "    'bbox': None},\n",
       "   {'text': 'TAKI', 'confidence': 0.998822808265686, 'bbox': None},\n",
       "   {'text': 'Gestion des reseaux sociaux et contenus graphiques',\n",
       "    'confidence': 0.9984609484672546,\n",
       "    'bbox': None},\n",
       "   {'text': 'EDDINE', 'confidence': 0.999838650226593, 'bbox': None},\n",
       "   {'text': 'Developpement', 'confidence': 0.9991694092750549, 'bbox': None},\n",
       "   {'text': 'des', 'confidence': 0.9997656345367432, 'bbox': None},\n",
       "   {'text': 'competences pedagogiques et communication',\n",
       "    'confidence': 0.9994933009147644,\n",
       "    'bbox': None},\n",
       "   {'text': 'PROJETS FREELANCE / PERSONNEL',\n",
       "    'confidence': 0.9838182330131531,\n",
       "    'bbox': None},\n",
       "   {'text': '2014 - 2022 (approx.)',\n",
       "    'confidence': 0.9892476201057434,\n",
       "    'bbox': None},\n",
       "   {'text': 'ECONOMISTE / ANALYSTE',\n",
       "    'confidence': 0.9915621876716614,\n",
       "    'bbox': None},\n",
       "   {'text': 'Personnalisation',\n",
       "    'confidence': 0.9708972573280334,\n",
       "    'bbox': None},\n",
       "   {'text': \"et publication d'applications mobiles\",\n",
       "    'confidence': 0.9964296221733093,\n",
       "    'bbox': None},\n",
       "   {'text': 'Technicien en', 'confidence': 0.9955673813819885, 'bbox': None},\n",
       "   {'text': 'Maintenance Informatique',\n",
       "    'confidence': 0.996826708316803,\n",
       "    'bbox': None},\n",
       "   {'text': 'Conception,', 'confidence': 0.9994758367538452, 'bbox': None},\n",
       "   {'text': 'assemblage', 'confidence': 0.9999158978462219, 'bbox': None},\n",
       "   {'text': 'et', 'confidence': 0.999931275844574, 'bbox': None},\n",
       "   {'text': 'revente', 'confidence': 0.99998539686203, 'bbox': None},\n",
       "   {'text': 'de', 'confidence': 0.999962329864502, 'bbox': None},\n",
       "   {'text': 'composants PC', 'confidence': 0.9734636545181274, 'bbox': None},\n",
       "   {'text': 'Design graphique',\n",
       "    'confidence': 0.9982438087463379,\n",
       "    'bbox': None},\n",
       "   {'text': 'e et', 'confidence': 0.8819323778152466, 'bbox': None},\n",
       "   {'text': 'projets', 'confidence': 0.9999615550041199, 'bbox': None},\n",
       "   {'text': 'numeriques', 'confidence': 0.9996572732925415, 'bbox': None},\n",
       "   {'text': 'personnels (logos,mini-sites web',\n",
       "    'confidence': 0.9997408390045166,\n",
       "    'bbox': None},\n",
       "   {'text': 'DEBAT / COMMUNICATION',\n",
       "    'confidence': 0.9838727116584778,\n",
       "    'bbox': None},\n",
       "   {'text': '- CLC', 'confidence': 0.9324272871017456, 'bbox': None},\n",
       "   {'text': 'OPEN DEBATE CENTER',\n",
       "    'confidence': 0.9991124272346497,\n",
       "    'bbox': None},\n",
       "   {'text': 'A PROPOS DE MOI', 'confidence': 0.9969425797462463, 'bbox': None},\n",
       "   {'text': 'MARRAKECH', 'confidence': 0.999800980091095, 'bbox': None},\n",
       "   {'text': '2013 -2014', 'confidence': 0.9384225010871887, 'bbox': None},\n",
       "   {'text': 'Finaliste et meilleur orateur en anglais',\n",
       "    'confidence': 0.9970110654830933,\n",
       "    'bbox': None},\n",
       "   {'text': 'Economiste', 'confidence': 0.9980486035346985, 'bbox': None},\n",
       "   {'text': 'de', 'confidence': 0.9999943375587463, 'bbox': None},\n",
       "   {'text': 'formation.', 'confidence': 0.9979751706123352, 'bbox': None},\n",
       "   {'text': 'appliquant', 'confidence': 0.9999407529830933, 'bbox': None},\n",
       "   {'text': 'Developpement des competences en communication et argumentation',\n",
       "    'confidence': 0.9862903356552124,\n",
       "    'bbox': None},\n",
       "   {'text': 'mes', 'confidence': 0.9997153878211975, 'bbox': None},\n",
       "   {'text': 'competences', 'confidence': 0.9996523261070251, 'bbox': None},\n",
       "   {'text': 'analytiques', 'confidence': 0.9996093511581421, 'bbox': None},\n",
       "   {'text': 's et', 'confidence': 0.9012343883514404, 'bbox': None},\n",
       "   {'text': 'mon', 'confidence': 0.9962640404701233, 'bbox': None},\n",
       "   {'text': 'savoir-faire', 'confidence': 0.9997563362121582, 'bbox': None},\n",
       "   {'text': 'a', 'confidence': 0.9012958407402039, 'bbox': None},\n",
       "   {'text': 'des', 'confidence': 0.9999868273735046, 'bbox': None},\n",
       "   {'text': 'projets', 'confidence': 0.9999305009841919, 'bbox': None},\n",
       "   {'text': 'concrets', 'confidence': 0.9999562501907349, 'bbox': None},\n",
       "   {'text': 'avec', 'confidence': 0.9997510313987732, 'bbox': None},\n",
       "   {'text': 'capacite', 'confidence': 0.9972130656242371, 'bbox': None},\n",
       "   {'text': \"d'a\", 'confidence': 0.9902566075325012, 'bbox': None},\n",
       "   {'text': 'adaptation', 'confidence': 0.9998019337654114, 'bbox': None},\n",
       "   {'text': 'selon', 'confidence': 0.9998704791069031, 'bbox': None},\n",
       "   {'text': 'le', 'confidence': 0.9993429780006409, 'bbox': None},\n",
       "   {'text': 'poste.', 'confidence': 0.9786259531974792, 'bbox': None},\n",
       "   {'text': 'EDUCATION', 'confidence': 0.9991047382354736, 'bbox': None},\n",
       "   {'text': 'LANGUES', 'confidence': 0.9999246597290039, 'bbox': None},\n",
       "   {'text': 'MASTER DE RECHERCHE EN ECONOMIE INTERNATIONALE,',\n",
       "    'confidence': 0.9960259795188904,\n",
       "    'bbox': None},\n",
       "   {'text': 'GOUVERNANCE ET DEVELOPPEMENT - FSJES MARRAKECH',\n",
       "    'confidence': 0.9959689378738403,\n",
       "    'bbox': None},\n",
       "   {'text': '2016 - Juillet 2018',\n",
       "    'confidence': 0.9863100647926331,\n",
       "    'bbox': None},\n",
       "   {'text': 'Arabe : Langue maternelle',\n",
       "    'confidence': 0.9734654426574707,\n",
       "    'bbox': None},\n",
       "   {'text': 'LICENCE FONDAMENTALE EN ECONOMIE ET GESTION - FSJES',\n",
       "    'confidence': 0.9956433176994324,\n",
       "    'bbox': None},\n",
       "   {'text': 'MARRAKECH', 'confidence': 0.9996767044067383, 'bbox': None},\n",
       "   {'text': '2013 - Juillet 2015',\n",
       "    'confidence': 0.9747419953346252,\n",
       "    'bbox': None},\n",
       "   {'text': 'Francais : Courant',\n",
       "    'confidence': 0.997857928276062,\n",
       "    'bbox': None},\n",
       "   {'text': 'DEUG EN ECONOMIE ET GESTION - FSJES MARRAKECH',\n",
       "    'confidence': 0.9869553446769714,\n",
       "    'bbox': None},\n",
       "   {'text': 'Anglais : Avance',\n",
       "    'confidence': 0.9952023029327393,\n",
       "    'bbox': None},\n",
       "   {'text': '2011 - Juillet 2013',\n",
       "    'confidence': 0.9764546751976013,\n",
       "    'bbox': None},\n",
       "   {'text': 'BACCALAUREAT TGC (TECHNIQUE DE GESTION COMPTABLE)',\n",
       "    'confidence': 0.9888929128646851,\n",
       "    'bbox': None},\n",
       "   {'text': 'LYCEE CHARIF AL EDRISSI, SAFI',\n",
       "    'confidence': 0.9878671765327454,\n",
       "    'bbox': None},\n",
       "   {'text': 'CONTACT', 'confidence': 0.99992835521698, 'bbox': None},\n",
       "   {'text': '2009 -Juillet 2011',\n",
       "    'confidence': 0.9656774997711182,\n",
       "    'bbox': None},\n",
       "   {'text': '1ERE ANNEE LYCEE - LYCEE HASSAN II, SAFI',\n",
       "    'confidence': 0.9955024719238281,\n",
       "    'bbox': None},\n",
       "   {'text': '2008 - 2009', 'confidence': 0.972230851650238, 'bbox': None},\n",
       "   {'text': 'DR Saada 1. IMM 133. Etage 1.',\n",
       "    'confidence': 0.9614500999450684,\n",
       "    'bbox': None},\n",
       "   {'text': 'COLLEGE - COLLEGE HANSALY, SAFI',\n",
       "    'confidence': 0.989554762840271,\n",
       "    'bbox': None},\n",
       "   {'text': 'Nr o2, Elizdihar, Marrakech',\n",
       "    'confidence': 0.9776405692100525,\n",
       "    'bbox': None},\n",
       "   {'text': '2005 - 2008', 'confidence': 0.9694030284881592, 'bbox': None},\n",
       "   {'text': 'PRIMAIRE, SAFI', 'confidence': 0.9961495399475098, 'bbox': None},\n",
       "   {'text': '06.05.32.81.59', 'confidence': 0.9987591505050659, 'bbox': None},\n",
       "   {'text': '2EME A 6EME ANNEE : ECOLE PRIMAIRE IBN BATOUTA,',\n",
       "    'confidence': 0.948256254196167,\n",
       "    'bbox': None},\n",
       "   {'text': '1ERE ANNEE : ECOLE PRIMAIRE ALLAL BEN ABDELLAH,',\n",
       "    'confidence': 0.9917734861373901,\n",
       "    'bbox': None},\n",
       "   {'text': '1999 - 2005', 'confidence': 0.9864525198936462, 'bbox': None},\n",
       "   {'text': 'tps://github.com/TakiEddineNaji',\n",
       "    'confidence': 0.9991738796234131,\n",
       "    'bbox': None},\n",
       "   {'text': 'Takieddine,naji@gmail.com',\n",
       "    'confidence': 0.9891049265861511,\n",
       "    'bbox': None},\n",
       "   {'text': 'CERTIFICATIONS & FORMATIONS COMPLEMENTAIRES',\n",
       "    'confidence': 0.9951852560043335,\n",
       "    'bbox': None},\n",
       "   {'text': 'COMPETENCES', 'confidence': 0.9994911551475525, 'bbox': None},\n",
       "   {'text': 'IBM', 'confidence': 0.9656721949577332, 'bbox': None},\n",
       "   {'text': 'Data Science Professional Certificate - 2025',\n",
       "    'confidence': 0.9860606789588928,\n",
       "    'bbox': None},\n",
       "   {'text': 'Data', 'confidence': 0.9997038245201111, 'bbox': None},\n",
       "   {'text': 'Analysis', 'confidence': 0.9997909665107727, 'bbox': None},\n",
       "   {'text': 'with', 'confidence': 0.9999756813049316, 'bbox': None},\n",
       "   {'text': 'Python', 'confidence': 0.9999244809150696, 'bbox': None},\n",
       "   {'text': 'PYTHON, SOL, DATA ANALYSIS, ML',\n",
       "    'confidence': 0.949887216091156,\n",
       "    'bbox': None},\n",
       "   {'text': 'Databases', 'confidence': 0.9999475479125977, 'bbox': None},\n",
       "   {'text': 'SQL', 'confidence': 0.9989460110664368, 'bbox': None},\n",
       "   {'text': 'for', 'confidence': 0.9998352527618408, 'bbox': None},\n",
       "   {'text': 'Data Science with Python',\n",
       "    'confidence': 0.9980019927024841,\n",
       "    'bbox': None},\n",
       "   {'text': 'and', 'confidence': 0.999975860118866, 'bbox': None},\n",
       "   {'text': 'Python', 'confidence': 0.999897301197052, 'bbox': None},\n",
       "   {'text': 'n for', 'confidence': 0.8644131422042847, 'bbox': None},\n",
       "   {'text': 'Data', 'confidence': 0.999936580657959, 'bbox': None},\n",
       "   {'text': 'Science, Al & Development',\n",
       "    'confidence': 0.9974479675292969,\n",
       "    'bbox': None},\n",
       "   {'text': 'PHOTOSHOP. ILLUSTRATOR. UNITY 3D',\n",
       "    'confidence': 0.9676541090011597,\n",
       "    'bbox': None},\n",
       "   {'text': 'Tools for', 'confidence': 0.9997227191925049, 'bbox': None},\n",
       "   {'text': 'Data', 'confidence': 0.9998870491981506, 'bbox': None},\n",
       "   {'text': 'Science', 'confidence': 0.9999042749404907, 'bbox': None},\n",
       "   {'text': 'PC ASSEMBLY & MAINTENANCE',\n",
       "    'confidence': 0.9941751956939697,\n",
       "    'bbox': None},\n",
       "   {'text': 'Data', 'confidence': 0.999934196472168, 'bbox': None},\n",
       "   {'text': 'Science', 'confidence': 0.9998931884765625, 'bbox': None},\n",
       "   {'text': 'Methodology', 'confidence': 0.999947190284729, 'bbox': None},\n",
       "   {'text': 'SOCIAL MEDIA & CONTENT/VIDEO DESIGN',\n",
       "    'confidence': 0.9996224641799927,\n",
       "    'bbox': None},\n",
       "   {'text': 'ALX', 'confidence': 0.9998359084129333, 'bbox': None},\n",
       "   {'text': 'AiCE', 'confidence': 0.9838569164276123, 'bbox': None},\n",
       "   {'text': 'Al', 'confidence': 0.9318884611129761, 'bbox': None},\n",
       "   {'text': 'Career', 'confidence': 0.9943883419036865, 'bbox': None},\n",
       "   {'text': 'Essentials- 2024',\n",
       "    'confidence': 0.9942766427993774,\n",
       "    'bbox': None},\n",
       "   {'text': 'DROJECT PLANNING & TROUBLESHOOTING',\n",
       "    'confidence': 0.9831821322441101,\n",
       "    'bbox': None}]}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Run all steps for a single CV\n",
    "# =====================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Preprocess PDF → PNG images\n",
    "# -------------------------------\n",
    "step1_folder = r\"C:\\ocr-pipeline\\step1_preprocess\"\n",
    "sys.path.append(step1_folder)\n",
    "\n",
    "from step1_preprocess_pdf import main as preprocess_pdf\n",
    "\n",
    "preprocess_pdf(\n",
    "    r\"C:\\ocr-pipeline\\step1_preprocess\\cv.pdf\",\n",
    "    r\"C:\\ocr-pipeline\\step1_preprocess\\step1_output\",\n",
    "    poppler_path=r\"C:\\poppler\\Library\\bin\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: OCR on processed images\n",
    "# -------------------------------\n",
    "step2_folder = r\"C:\\ocr-pipeline\\step2_ocr\"\n",
    "sys.path.append(step2_folder)\n",
    "\n",
    "from step2_ocr_paddle import run_ocr  # import the function\n",
    "\n",
    "run_ocr(\n",
    "    r\"C:\\ocr-pipeline\\step1_preprocess\\step1_output\",\n",
    "    r\"C:\\ocr-pipeline\\step2_ocr\\step2_output\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Light cleaning OCR results\n",
    "# -------------------------------\n",
    "step3_folder = r\"C:\\ocr-pipeline\\step3_lightclean\"\n",
    "sys.path.append(step3_folder)\n",
    "from step3_light_clean import clean_ocr_json\n",
    "\n",
    "clean_ocr_json(\n",
    "    r\"C:\\ocr-pipeline\\step2_ocr\\step2_output\\cv_ocr_raw.json\",\n",
    "    r\"C:\\ocr-pipeline\\step3_lightclean\\step3_output\\cv_ocr_cleaned.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee9ae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ocr-pipeline\\ocrproject\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing CV: 11943065 ===\n",
      "[STEP 1] Processed 2 pages → C:\\ocr-pipeline\\caller_batch\\step1_batch_output\\11943065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ocr-pipeline\\ocrproject\\Lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\latin_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR → processed_1.png\n",
      "OCR → processed_2.png\n",
      "[STEP 2] OCR output saved → C:\\ocr-pipeline\\caller_batch\\step2_batch_output\\11943065\\cv_ocr_raw.json\n",
      "[STEP 3] Cleaned OCR saved → C:\\ocr-pipeline\\caller_batch\\step3_batch_output\\11943065\\cv_ocr_cleaned.json\n",
      "[DONE] 11943065\n",
      "\n",
      "=== Processing CV: 12071138 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP 1] Processed 3 pages → C:\\ocr-pipeline\\caller_batch\\step1_batch_output\\12071138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\latin_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR → processed_1.png\n",
      "OCR → processed_2.png\n",
      "OCR → processed_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP 2] OCR output saved → C:\\ocr-pipeline\\caller_batch\\step2_batch_output\\12071138\\cv_ocr_raw.json\n",
      "[STEP 3] Cleaned OCR saved → C:\\ocr-pipeline\\caller_batch\\step3_batch_output\\12071138\\cv_ocr_cleaned.json\n",
      "[DONE] 12071138\n",
      "\n",
      "=== Processing CV: exemple-cv-etudiant-1 ===\n",
      "[STEP 1] Processed 1 pages → C:\\ocr-pipeline\\caller_batch\\step1_batch_output\\exemple-cv-etudiant-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\latin_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR → processed_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP 2] OCR output saved → C:\\ocr-pipeline\\caller_batch\\step2_batch_output\\exemple-cv-etudiant-1\\cv_ocr_raw.json\n",
      "[STEP 3] Cleaned OCR saved → C:\\ocr-pipeline\\caller_batch\\step3_batch_output\\exemple-cv-etudiant-1\\cv_ocr_cleaned.json\n",
      "[DONE] exemple-cv-etudiant-1\n",
      "\n",
      "=== Processing CV: exemple-cv-lyceen-1 ===\n",
      "[STEP 1] Processed 1 pages → C:\\ocr-pipeline\\caller_batch\\step1_batch_output\\exemple-cv-lyceen-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\latin_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR → processed_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP 2] OCR output saved → C:\\ocr-pipeline\\caller_batch\\step2_batch_output\\exemple-cv-lyceen-1\\cv_ocr_raw.json\n",
      "[STEP 3] Cleaned OCR saved → C:\\ocr-pipeline\\caller_batch\\step3_batch_output\\exemple-cv-lyceen-1\\cv_ocr_cleaned.json\n",
      "[DONE] exemple-cv-lyceen-1\n",
      "\n",
      "=== Processing CV: Screenshot 2026-01-01 212822 ===\n",
      "[STEP 1] Processed 1 pages → C:\\ocr-pipeline\\caller_batch\\step1_batch_output\\Screenshot 2026-01-01 212822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\undop\\.paddlex\\official_models\\latin_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR → processed_1.png\n",
      "[STEP 2] OCR output saved → C:\\ocr-pipeline\\caller_batch\\step2_batch_output\\Screenshot 2026-01-01 212822\\cv_ocr_raw.json\n",
      "[STEP 3] Cleaned OCR saved → C:\\ocr-pipeline\\caller_batch\\step3_batch_output\\Screenshot 2026-01-01 212822\\cv_ocr_cleaned.json\n",
      "[DONE] Screenshot 2026-01-01 212822\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# STEP 3 CALLER — Batch process multiple CVs\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# =====================================================\n",
    "# CONFIG\n",
    "# =====================================================\n",
    "CV_INPUT_DIR = Path(r\"C:\\ocr-pipeline\\caller_batch\\cvs_input\")\n",
    "\n",
    "BASE_STEP1_OUT = Path(r\"C:\\ocr-pipeline\\caller_batch\\step1_batch_output\")\n",
    "BASE_STEP2_OUT = Path(r\"C:\\ocr-pipeline\\caller_batch\\step2_batch_output\")\n",
    "BASE_STEP3_OUT = Path(r\"C:\\ocr-pipeline\\caller_batch\\step3_batch_output\")\n",
    "\n",
    "POPPLER_PATH = r\"C:\\poppler\\Library\\bin\"\n",
    "\n",
    "# =====================================================\n",
    "# STEP 1 IMPORT\n",
    "# =====================================================\n",
    "step1_folder = r\"C:\\ocr-pipeline\\step1_preprocess\"\n",
    "sys.path.append(step1_folder)\n",
    "from step1_preprocess_pdf import main as preprocess_file  # updated: handles PDF + images\n",
    "\n",
    "# =====================================================\n",
    "# STEP 2 IMPORT\n",
    "# =====================================================\n",
    "step2_folder = r\"C:\\ocr-pipeline\\step2_ocr\"\n",
    "sys.path.append(step2_folder)\n",
    "from step2_ocr_paddle import run_ocr\n",
    "\n",
    "# =====================================================\n",
    "# STEP 3 IMPORT\n",
    "# =====================================================\n",
    "step3_folder = r\"C:\\ocr-pipeline\\step3_lightclean\"\n",
    "sys.path.append(step3_folder)\n",
    "from step3_light_clean import clean_ocr_json\n",
    "\n",
    "# =====================================================\n",
    "# BATCH PIPELINE\n",
    "# =====================================================\n",
    "# Accept PDFs + PNG + JPG + JPEG\n",
    "VALID_EXTENSIONS = [\".pdf\", \".png\", \".jpg\", \".jpeg\"]\n",
    "\n",
    "for file_path in CV_INPUT_DIR.glob(\"*\"):\n",
    "    if file_path.suffix.lower() not in VALID_EXTENSIONS:\n",
    "        continue\n",
    "\n",
    "    cv_name = file_path.stem\n",
    "    print(f\"\\n=== Processing CV: {cv_name} ===\")\n",
    "\n",
    "    # Per-CV folders\n",
    "    step1_out = BASE_STEP1_OUT / cv_name\n",
    "    step2_out = BASE_STEP2_OUT / cv_name\n",
    "    step3_out = BASE_STEP3_OUT / cv_name\n",
    "    step3_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 1: PDF / Image → PNG (preprocessing)\n",
    "    # -------------------------------\n",
    "    try:\n",
    "        preprocess_file(\n",
    "            str(file_path),\n",
    "            str(step1_out),\n",
    "            poppler_path=POPPLER_PATH\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Step 1 failed for {cv_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 2: OCR\n",
    "    # -------------------------------\n",
    "    try:\n",
    "        run_ocr(\n",
    "            str(step1_out),\n",
    "            str(step2_out)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Step 2 failed for {cv_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 3: Light Clean\n",
    "    # -------------------------------\n",
    "    raw_json = step2_out / \"cv_ocr_raw.json\"\n",
    "    clean_json = step3_out / \"cv_ocr_cleaned.json\"\n",
    "\n",
    "    if not raw_json.exists():\n",
    "        print(f\"[SKIP] No OCR output for {cv_name}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        clean_ocr_json(\n",
    "            str(raw_json),\n",
    "            str(clean_json)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Step 3 failed for {cv_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"[DONE] {cv_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ba995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ocr-pipeline\\ocrproject\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP 5] Stored 3 embeddings in Chroma\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Step 5: Embeddings\n",
    "# =====================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "step5_folder = r\"C:\\ocr-pipeline\\step5_embeddings\"\n",
    "sys.path.append(step5_folder)\n",
    "\n",
    "from step5_embeddings import main as build_embeddings\n",
    "\n",
    "build_embeddings(\n",
    "    r\"C:\\ocr-pipeline\\step4_rag\\step4_output\\cv_rag_blocks.json\",\n",
    "    r\"C:\\ocr-pipeline\\step5_embeddings\\step5_output\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd36c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 6] Retrieved blocks:\n",
      "\n",
      "Doc: cv_001 | Page: 1\n",
      "EXPERIENCES / PROJETS APPRENTISSAGE EN DATA SCIENCE - AUTOFORMATION / PROJETS PERSONNELS 2024 - Present Formation en Data Science et Machine Learning (Python, Pandas) FORMATEUR / RESPONSABLE PEDAGOGIQUE - SUP'CENTER, MARRAKECH 2019 - 2022 NAJI Soutien en eco internationale/developpement et informati \n",
      "\n",
      "Doc: cv_001 | Page: 1\n",
      "Nr o2, Elizdihar, Marrakech 2005 - 2008 PRIMAIRE, SAFI 06.05.32.81.59 2EME A 6EME ANNEE : ECOLE PRIMAIRE IBN BATOUTA, 1ERE ANNEE : ECOLE PRIMAIRE ALLAL BEN ABDELLAH, 1999 - 2005 tps://github.com/TakiEddineNaji Takieddine,naji@gmail.com CERTIFICATIONS & FORMATIONS COMPLEMENTAIRES COMPETENCES IBM Data \n",
      "\n",
      "Doc: cv_001 | Page: 1\n",
      "Economiste de formation. appliquant Developpement des competences en communication et argumentation mes competences analytiques s et mon savoir-faire a des projets concrets avec capacite d'a adaptation selon le poste. EDUCATION LANGUES MASTER DE RECHERCHE EN ECONOMIE INTERNATIONALE, GOUVERNANCE ET D \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['block_0', 'block_2', 'block_1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"EXPERIENCES / PROJETS APPRENTISSAGE EN DATA SCIENCE - AUTOFORMATION / PROJETS PERSONNELS 2024 - Present Formation en Data Science et Machine Learning (Python, Pandas) FORMATEUR / RESPONSABLE PEDAGOGIQUE - SUP'CENTER, MARRAKECH 2019 - 2022 NAJI Soutien en eco internationale/developpement et informatique de gestion Enseignement en ligne et presentiel TAKI Gestion des reseaux sociaux et contenus graphiques EDDINE Developpement des competences pedagogiques et communication PROJETS FREELANCE / PERSONNEL 2014 - 2022 (approx.) ECONOMISTE / ANALYSTE Personnalisation et publication d'applications mobiles Technicien en Maintenance Informatique Conception, assemblage et revente de composants PC Design graphique e et projets numeriques personnels (logos,mini-sites web DEBAT / COMMUNICATION - CLC OPEN DEBATE CENTER A PROPOS DE MOI MARRAKECH 2013 -2014 Finaliste et meilleur orateur en anglais\",\n",
       "   'Nr o2, Elizdihar, Marrakech 2005 - 2008 PRIMAIRE, SAFI 06.05.32.81.59 2EME A 6EME ANNEE : ECOLE PRIMAIRE IBN BATOUTA, 1ERE ANNEE : ECOLE PRIMAIRE ALLAL BEN ABDELLAH, 1999 - 2005 tps://github.com/TakiEddineNaji Takieddine,naji@gmail.com CERTIFICATIONS & FORMATIONS COMPLEMENTAIRES COMPETENCES IBM Data Science Professional Certificate - 2025 Data Analysis with Python PYTHON, SOL, DATA ANALYSIS, ML Databases SQL for Data Science with Python and Python n for Data Science, Al & Development PHOTOSHOP. ILLUSTRATOR. UNITY 3D Tools for Data Science PC ASSEMBLY & MAINTENANCE Data Science Methodology SOCIAL MEDIA & CONTENT/VIDEO DESIGN ALX AiCE Al Career Essentials- 2024 DROJECT PLANNING & TROUBLESHOOTING',\n",
       "   \"Economiste de formation. appliquant Developpement des competences en communication et argumentation mes competences analytiques s et mon savoir-faire a des projets concrets avec capacite d'a adaptation selon le poste. EDUCATION LANGUES MASTER DE RECHERCHE EN ECONOMIE INTERNATIONALE, GOUVERNANCE ET DEVELOPPEMENT - FSJES MARRAKECH 2016 - Juillet 2018 Arabe : Langue maternelle LICENCE FONDAMENTALE EN ECONOMIE ET GESTION - FSJES MARRAKECH 2013 - Juillet 2015 Francais : Courant DEUG EN ECONOMIE ET GESTION - FSJES MARRAKECH Anglais : Avance 2011 - Juillet 2013 BACCALAUREAT TGC (TECHNIQUE DE GESTION COMPTABLE) LYCEE CHARIF AL EDRISSI, SAFI CONTACT 2009 -Juillet 2011 1ERE ANNEE LYCEE - LYCEE HASSAN II, SAFI 2008 - 2009 DR Saada 1. IMM 133. Etage 1. COLLEGE - COLLEGE HANSALY, SAFI\"]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'doc_id': 'cv_001', 'page': 1, 'block_id': 0},\n",
       "   {'block_id': 2, 'page': 1, 'doc_id': 'cv_001'},\n",
       "   {'page': 1, 'block_id': 1, 'doc_id': 'cv_001'}]],\n",
       " 'distances': [[1.0522534847259521, 1.272376298904419, 1.529874563217163]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Step 6: Retrieval (Chroma)\n",
    "# =====================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "step6_folder = r\"C:\\ocr-pipeline\\step6_retrieval\"\n",
    "sys.path.append(step6_folder)\n",
    "\n",
    "from step6_retrieval import main as retrieve_blocks\n",
    "\n",
    "retrieve_blocks(\n",
    "    r\"C:\\ocr-pipeline\\step5_embeddings\\step5_output\",\n",
    "    \"What experience does the candidate have in data science?\",\n",
    "    3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
